{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP1Jr4obNY83+vuUHlWTXTP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eumcloud/HHPLUS_AI/blob/main/week01/02_1_3_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch import nn\n",
        "from torch.optim import SGD, Adam\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "transform = transforms.ToTensor()\n",
        "# transform = transforms.Compose([\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "# ])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "\n",
        "\n",
        "batch_size = 256\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "# CIFAR10 입력 shape 확인\n",
        "print(\"입력 이미지 shape:\", trainset[0][0].shape)\n"
      ],
      "metadata": {
        "id": "vTPNK0xpAXCE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33dec14b-38cf-4ddd-d53d-b9d36f5b0c2f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:03<00:00, 48.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 이미지 shape: torch.Size([3, 32, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 정확도 측정 함수\n",
        "def accuracy(model, dataloader):\n",
        "    cnt = 0\n",
        "    acc = 0\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        for data in dataloader:\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
        "            preds = model(inputs)\n",
        "            preds = torch.argmax(preds, dim=-1)\n",
        "            acc += (labels == preds).sum().item()\n",
        "            cnt += labels.size(0)\n",
        "    return acc / cnt\n",
        "\n",
        "# 정확도 plot 함수\n",
        "def plot_acc(acc_list1, acc_list2, label1, label2, title):\n",
        "    x = np.arange(len(acc_list1))\n",
        "    plt.plot(x, acc_list1, label=label1)\n",
        "    plt.plot(x, acc_list2, label=label2)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "UF-VfY1rAvEr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LeakyReLUModel(nn.Module):\n",
        "    def __init__(self, input_dim, n_dim):\n",
        "        super().__init__()\n",
        "        self.layer1 = nn.Linear(input_dim, n_dim)\n",
        "        self.layer2 = nn.Linear(n_dim, n_dim)\n",
        "        self.layer3 = nn.Linear(n_dim, 10)\n",
        "        self.act = nn.LeakyReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = self.act(self.layer1(x))\n",
        "        x = self.act(self.layer2(x))\n",
        "        x = self.layer3(x)\n",
        "        return x\n",
        "\n",
        "# Sigmoid 모델 정의\n",
        "class SigmoidModel(LeakyReLUModel):\n",
        "    def __init__(self, input_dim, n_dim):\n",
        "        super().__init__(input_dim, n_dim)\n",
        "        self.act = nn.Sigmoid()\n",
        "\n",
        "# Dropout 모델 정의\n",
        "class DropoutModel(nn.Module):\n",
        "    def __init__(self, input_dim, n_dim, dropout_prob=0.1):\n",
        "        super().__init__()\n",
        "        self.layer1 = nn.Linear(input_dim, n_dim)\n",
        "        self.layer2 = nn.Linear(n_dim, n_dim)\n",
        "        self.layer3 = nn.Linear(n_dim, 10)\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "        self.act = nn.LeakyReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = self.dropout(self.act(self.layer1(x)))\n",
        "        x = self.dropout(self.act(self.layer2(x)))\n",
        "        x = self.layer3(x)\n",
        "        return x\n",
        "\n",
        "# 학습 함수\n",
        "def train_model(model, optimizer, criterion, n_epochs=50):\n",
        "    model = model.to('cuda')\n",
        "    train_accs = []\n",
        "    test_accs = []\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0.\n",
        "        for data in trainloader:\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(inputs)\n",
        "            loss = criterion(preds, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        train_acc = accuracy(model, trainloader)\n",
        "        test_acc = accuracy(model, testloader)\n",
        "        train_accs.append(train_acc)\n",
        "        test_accs.append(test_acc)\n",
        "\n",
        "        print(f\"Epoch {epoch:2d} | Loss: {total_loss:.4f} | Train Acc: {train_acc:.4f} | Test Acc: {test_acc:.4f}\")\n",
        "\n",
        "    return train_accs, test_accs\n"
      ],
      "metadata": {
        "id": "uPfZU47Zo5Uu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKU8pOcR9CUd",
        "outputId": "78958166-9490-49cd-9b22-7daf85a570bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  0 | Loss: 450.1350 | Train Acc: 0.1002 | Test Acc: 0.0998\n",
            "Epoch  1 | Loss: 448.1040 | Train Acc: 0.1034 | Test Acc: 0.1042\n",
            "Epoch  2 | Loss: 446.2705 | Train Acc: 0.1146 | Test Acc: 0.1147\n",
            "Epoch  3 | Loss: 444.3824 | Train Acc: 0.1396 | Test Acc: 0.1431\n",
            "Epoch  4 | Loss: 442.4351 | Train Acc: 0.1683 | Test Acc: 0.1734\n",
            "Epoch  5 | Loss: 440.3672 | Train Acc: 0.1955 | Test Acc: 0.1988\n",
            "Epoch  6 | Loss: 438.1144 | Train Acc: 0.2119 | Test Acc: 0.2127\n",
            "Epoch  7 | Loss: 435.6623 | Train Acc: 0.2275 | Test Acc: 0.2244\n",
            "Epoch  8 | Loss: 433.0208 | Train Acc: 0.2362 | Test Acc: 0.2322\n",
            "Epoch  9 | Loss: 430.2185 | Train Acc: 0.2484 | Test Acc: 0.2459\n",
            "Epoch 10 | Loss: 427.2847 | Train Acc: 0.2537 | Test Acc: 0.2505\n",
            "Epoch 11 | Loss: 424.2535 | Train Acc: 0.2616 | Test Acc: 0.2568\n",
            "Epoch 12 | Loss: 421.2255 | Train Acc: 0.2682 | Test Acc: 0.2637\n",
            "Epoch 13 | Loss: 418.2208 | Train Acc: 0.2715 | Test Acc: 0.2708\n",
            "Epoch 14 | Loss: 415.3321 | Train Acc: 0.2734 | Test Acc: 0.2725\n",
            "Epoch 15 | Loss: 412.5810 | Train Acc: 0.2739 | Test Acc: 0.2747\n",
            "Epoch 16 | Loss: 410.0167 | Train Acc: 0.2815 | Test Acc: 0.2820\n",
            "Epoch 17 | Loss: 407.5639 | Train Acc: 0.2844 | Test Acc: 0.2854\n",
            "Epoch 18 | Loss: 405.2722 | Train Acc: 0.2866 | Test Acc: 0.2873\n",
            "Epoch 19 | Loss: 403.2244 | Train Acc: 0.2930 | Test Acc: 0.2905\n",
            "Epoch 20 | Loss: 401.1228 | Train Acc: 0.2918 | Test Acc: 0.2899\n",
            "Epoch 21 | Loss: 399.2785 | Train Acc: 0.2943 | Test Acc: 0.2917\n",
            "Epoch 22 | Loss: 397.3844 | Train Acc: 0.2973 | Test Acc: 0.2946\n",
            "Epoch 23 | Loss: 395.6216 | Train Acc: 0.2992 | Test Acc: 0.2960\n",
            "Epoch 24 | Loss: 393.9862 | Train Acc: 0.2996 | Test Acc: 0.2962\n",
            "Epoch 25 | Loss: 392.4303 | Train Acc: 0.3013 | Test Acc: 0.2960\n",
            "Epoch 26 | Loss: 390.9402 | Train Acc: 0.3031 | Test Acc: 0.3010\n",
            "Epoch 27 | Loss: 389.5303 | Train Acc: 0.3048 | Test Acc: 0.2996\n",
            "Epoch 28 | Loss: 388.1466 | Train Acc: 0.3059 | Test Acc: 0.3019\n",
            "Epoch 29 | Loss: 386.8455 | Train Acc: 0.3097 | Test Acc: 0.3037\n",
            "Epoch 30 | Loss: 385.5560 | Train Acc: 0.3113 | Test Acc: 0.3058\n",
            "Epoch 31 | Loss: 384.4082 | Train Acc: 0.3149 | Test Acc: 0.3093\n",
            "Epoch 32 | Loss: 383.2253 | Train Acc: 0.3155 | Test Acc: 0.3098\n",
            "Epoch 33 | Loss: 382.1002 | Train Acc: 0.3160 | Test Acc: 0.3113\n",
            "Epoch 34 | Loss: 381.0088 | Train Acc: 0.3186 | Test Acc: 0.3134\n",
            "Epoch 35 | Loss: 380.1106 | Train Acc: 0.3207 | Test Acc: 0.3158\n",
            "Epoch 36 | Loss: 379.0479 | Train Acc: 0.3217 | Test Acc: 0.3178\n",
            "Epoch 37 | Loss: 378.2084 | Train Acc: 0.3237 | Test Acc: 0.3186\n",
            "Epoch 38 | Loss: 377.2726 | Train Acc: 0.3253 | Test Acc: 0.3196\n",
            "Epoch 39 | Loss: 376.4832 | Train Acc: 0.3247 | Test Acc: 0.3193\n",
            "Epoch 40 | Loss: 375.6186 | Train Acc: 0.3276 | Test Acc: 0.3218\n",
            "Epoch 41 | Loss: 374.9142 | Train Acc: 0.3285 | Test Acc: 0.3222\n",
            "Epoch 42 | Loss: 374.0967 | Train Acc: 0.3297 | Test Acc: 0.3264\n",
            "Epoch 43 | Loss: 373.3499 | Train Acc: 0.3318 | Test Acc: 0.3280\n",
            "Epoch 44 | Loss: 372.7201 | Train Acc: 0.3329 | Test Acc: 0.3294\n",
            "Epoch 45 | Loss: 371.9155 | Train Acc: 0.3331 | Test Acc: 0.3287\n",
            "Epoch 46 | Loss: 371.2916 | Train Acc: 0.3349 | Test Acc: 0.3308\n",
            "Epoch 47 | Loss: 370.5908 | Train Acc: 0.3376 | Test Acc: 0.3321\n",
            "Epoch 48 | Loss: 369.9370 | Train Acc: 0.3383 | Test Acc: 0.3327\n",
            "Epoch 49 | Loss: 369.3210 | Train Acc: 0.3396 | Test Acc: 0.3334\n",
            "Epoch  0 | Loss: 366.7700 | Train Acc: 0.3903 | Test Acc: 0.3918\n",
            "Epoch  1 | Loss: 325.0260 | Train Acc: 0.4317 | Test Acc: 0.4243\n",
            "Epoch  2 | Loss: 307.4846 | Train Acc: 0.4687 | Test Acc: 0.4605\n",
            "Epoch  3 | Loss: 293.1075 | Train Acc: 0.4890 | Test Acc: 0.4804\n",
            "Epoch  4 | Loss: 284.9541 | Train Acc: 0.4810 | Test Acc: 0.4624\n",
            "Epoch  5 | Loss: 276.8993 | Train Acc: 0.5086 | Test Acc: 0.4888\n",
            "Epoch  6 | Loss: 268.8250 | Train Acc: 0.5211 | Test Acc: 0.4934\n",
            "Epoch  7 | Loss: 263.9816 | Train Acc: 0.5368 | Test Acc: 0.5012\n",
            "Epoch  8 | Loss: 257.7572 | Train Acc: 0.5351 | Test Acc: 0.4986\n",
            "Epoch  9 | Loss: 252.7318 | Train Acc: 0.5468 | Test Acc: 0.5073\n",
            "Epoch 10 | Loss: 248.0966 | Train Acc: 0.5625 | Test Acc: 0.5128\n",
            "Epoch 11 | Loss: 241.4266 | Train Acc: 0.5606 | Test Acc: 0.5030\n",
            "Epoch 12 | Loss: 235.4554 | Train Acc: 0.5762 | Test Acc: 0.5215\n",
            "Epoch 13 | Loss: 229.4517 | Train Acc: 0.6058 | Test Acc: 0.5334\n",
            "Epoch 14 | Loss: 224.1149 | Train Acc: 0.6044 | Test Acc: 0.5185\n",
            "Epoch 15 | Loss: 221.1945 | Train Acc: 0.6110 | Test Acc: 0.5217\n",
            "Epoch 16 | Loss: 212.6488 | Train Acc: 0.6320 | Test Acc: 0.5280\n",
            "Epoch 17 | Loss: 209.0554 | Train Acc: 0.6346 | Test Acc: 0.5170\n",
            "Epoch 18 | Loss: 203.2967 | Train Acc: 0.6551 | Test Acc: 0.5342\n",
            "Epoch 19 | Loss: 198.3686 | Train Acc: 0.6660 | Test Acc: 0.5326\n",
            "Epoch 20 | Loss: 193.5278 | Train Acc: 0.6614 | Test Acc: 0.5301\n",
            "Epoch 21 | Loss: 188.2475 | Train Acc: 0.6877 | Test Acc: 0.5393\n",
            "Epoch 22 | Loss: 181.1273 | Train Acc: 0.6871 | Test Acc: 0.5341\n",
            "Epoch 23 | Loss: 177.2266 | Train Acc: 0.6974 | Test Acc: 0.5340\n",
            "Epoch 24 | Loss: 171.4255 | Train Acc: 0.6826 | Test Acc: 0.5196\n",
            "Epoch 25 | Loss: 167.3013 | Train Acc: 0.7048 | Test Acc: 0.5324\n",
            "Epoch 26 | Loss: 161.9447 | Train Acc: 0.7234 | Test Acc: 0.5279\n",
            "Epoch 27 | Loss: 155.7121 | Train Acc: 0.7392 | Test Acc: 0.5385\n",
            "Epoch 28 | Loss: 151.1695 | Train Acc: 0.7490 | Test Acc: 0.5286\n"
          ]
        }
      ],
      "source": [
        "# 1. SGD vs Adam (LeakyReLU 사용)\n",
        "model_sgd = LeakyReLUModel(3 * 32 * 32, 1024)\n",
        "model_adam = LeakyReLUModel(3 * 32 * 32, 1024)\n",
        "\n",
        "acc_sgd, _ = train_model(model_sgd, SGD(model_sgd.parameters(), lr=0.001), nn.CrossEntropyLoss())\n",
        "acc_adam, _ = train_model(model_adam, Adam(model_adam.parameters(), lr=0.001), nn.CrossEntropyLoss())\n",
        "plot_acc(acc_sgd, acc_adam, \"SGD\", \"Adam\", \"Train Accuracy: SGD vs Adam\")\n",
        "\n",
        "# 2. LeakyReLU vs Sigmoid (둘 다 Adam 사용)\n",
        "model_relu = LeakyReLUModel(3 * 32 * 32, 1024)\n",
        "model_sigmoid = SigmoidModel(3 * 32 * 32, 1024)\n",
        "\n",
        "acc_relu, _ = train_model(model_relu, Adam(model_relu.parameters(), lr=0.001), nn.CrossEntropyLoss())\n",
        "acc_sigmoid, _ = train_model(model_sigmoid, Adam(model_sigmoid.parameters(), lr=0.001), nn.CrossEntropyLoss())\n",
        "plot_acc(acc_relu, acc_sigmoid, \"LeakyReLU\", \"Sigmoid\", \"Train Accuracy: LeakyReLU vs Sigmoid\")\n",
        "\n",
        "# 3. Dropout 모델 (Adam 사용) - Train/Test Accuracy 비교\n",
        "model_dropout = DropoutModel(3 * 32 * 32, 1024)\n",
        "acc_train_dropout, acc_test_dropout = train_model(model_dropout, Adam(model_dropout.parameters(), lr=0.001), nn.CrossEntropyLoss())\n",
        "plot_acc(acc_train_dropout, acc_test_dropout, \"Train\", \"Test\", \"Dropout Model: Train vs Test Accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Hyperparameters\n",
        "n_epochs = 50\n",
        "batch_size = 256\n",
        "\n",
        "# Load CIFAR10 dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "wTSeFyOe9F5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define models\n",
        "class BaseModel(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 10)\n",
        "        self.act = nn.LeakyReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = self.act(self.fc1(x))\n",
        "        x = self.act(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "class DropoutModel(nn.Module):\n",
        "    def __init__(self, input_dim, dropout_rate=0.3):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 10)\n",
        "        self.act = nn.LeakyReLU()\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = self.dropout(self.act(self.fc1(x)))\n",
        "        x = self.dropout(self.act(self.fc2(x)))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Accuracy calculation function\n",
        "def calculate_accuracy(model, dataloader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    model.eval() # Ensure model is in evaluation mode\n",
        "    with torch.no_grad():\n",
        "        for data in dataloader:\n",
        "            images, labels = data[0].to(device), data[1].to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return correct / total\n",
        "\n",
        "# Training function\n",
        "def train_model(model, optimizer, criterion, train_loader, test_loader, epochs):\n",
        "    train_acc_history = []\n",
        "    test_acc_history = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train() # Ensure model is in training mode\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(train_loader, 0):\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        train_acc = calculate_accuracy(model, train_loader)\n",
        "        test_acc = calculate_accuracy(model, test_loader)\n",
        "        train_acc_history.append(train_acc)\n",
        "        test_acc_history.append(test_acc)\n",
        "\n",
        "        print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}, Train Accuracy: {train_acc:.4f}, Test Accuracy: {test_acc:.4f}')\n",
        "\n",
        "    return train_acc_history, test_acc_history\n",
        "\n",
        "# Initialize models\n",
        "input_dim = 32 * 32 * 3 # CIFAR10 image size\n",
        "base_model = BaseModel(input_dim).to(device)\n",
        "dropout_model = DropoutModel(input_dim).to(device)\n",
        "\n",
        "# Define loss function and optimizers\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "base_optimizer = optim.Adam(base_model.parameters(), lr=0.001)\n",
        "dropout_optimizer = optim.Adam(dropout_model.parameters(), lr=0.001)\n",
        "\n",
        "# Train models\n",
        "print(\"Training Base Model:\")\n",
        "base_train_acc, base_test_acc = train_model(base_model, base_optimizer, criterion, trainloader, testloader, n_epochs)\n",
        "\n",
        "print(\"\\nTraining Dropout Model:\")\n",
        "dropout_train_acc, dropout_test_acc = train_model(dropout_model, dropout_optimizer, criterion, trainloader, testloader, n_epochs)\n",
        "\n",
        "# Plot results\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(range(1, n_epochs+1), base_train_acc, label='Base Model - Train')\n",
        "plt.plot(range(1, n_epochs+1), base_test_acc, label='Base Model - Test')\n",
        "plt.plot(range(1, n_epochs+1), dropout_train_acc, label='Dropout Model - Train')\n",
        "plt.plot(range(1, n_epochs+1), dropout_test_acc, label='Dropout Model - Test')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Base Model vs Dropout Model: Train and Test Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Print final accuracies\n",
        "print(f\"Base Model - Final Train Accuracy: {base_train_acc[-1]:.4f}, Test Accuracy: {base_test_acc[-1]:.4f}\")\n",
        "print(f\"Dropout Model - Final Train Accuracy: {dropout_train_acc[-1]:.4f}, Test Accuracy: {dropout_test_acc[-1]:.4f}\")"
      ],
      "metadata": {
        "id": "1C0THX-t4KLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9OU3YZ1nKtRL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}